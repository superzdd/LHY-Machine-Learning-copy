{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superzdd/LHY-Machine-Learning-copy/blob/main/hw02/ML2023Spring_HW2_zdd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2: Phoneme Classification**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7DRC5V7_8A5"
      },
      "source": [
        "Objectives:\n",
        "* Solve a classification problem with deep neural networks (DNNs).\n",
        "* Understand recursive neural networks (RNNs).\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL1VUBOXNYZJ"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [],
        "id": "EUPdnpmiNYZK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import datetime\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X57zzYXCNYZK"
      },
      "source": [
        "# Environment Confirmation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGDYdJ6zNYZK",
        "outputId": "36e1f9ab-88b5-480d-9b4e-55d8e2d9c892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 17 07:42:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    32W /  70W |   1035MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6wSpwCsNYZL",
        "outputId": "aea1b651-a155-4233-e24b-983a355c6366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "free memory: param already deleted.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# 获取当前工作环境\n",
        "def KaggleColabLocal():\n",
        "    env = dict(\n",
        "        inKaggle=False,\n",
        "        inColab=False,\n",
        "        inLocal=False\n",
        "    )\n",
        "\n",
        "    # 检查是否在Kaggle环境中\n",
        "    if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ and os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive':\n",
        "        # print(\"在Kaggle环境中运行\")\n",
        "        env['inKaggle'] = True\n",
        "    # 检查是否在Colab环境中\n",
        "    elif 'google.colab' in str(get_ipython()):\n",
        "        # print(\"在Colab环境中运行\")\n",
        "        env['inColab'] = True\n",
        "    # 检查是否在本地JupyterLab环境中\n",
        "    elif 'JPY_PARENT_PID' in os.environ:\n",
        "        # print(\"在本地JupyterLab环境中运行\")\n",
        "        env['inLocal'] = True\n",
        "    else:\n",
        "        print(\"在其他环境中运行\")\n",
        "    return env\n",
        "\n",
        "\n",
        "KaggleColabLocal()\n",
        "\n",
        "try:\n",
        "    del train_set,val_set\n",
        "    del train_loader,val_loader\n",
        "except:\n",
        "    print(\"free memory: param already deleted.\")\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj",
        "tags": []
      },
      "source": [
        "# Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`: training metadata\n",
        "- `libriphone/train_labels`: training labels\n",
        "- `libriphone/test_split.txt`: testing metadata\n",
        "- `libriphone/feat/train/*.pt`: training feature\n",
        "- `libriphone/feat/test/*.pt`:  testing feature\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the google drive link is dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2023spring-hw2/data) and upload it to the workspace.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OzkiMEcC3Foq",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b0da1b3-0789-485f-8e3e-3f2d85e53873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data File already exist.Skip!\n"
          ]
        }
      ],
      "source": [
        "Current_Env = KaggleColabLocal() # 获取当前环境\n",
        "\n",
        "# 如果文件已经下载，那不用重新下载文件\n",
        "commonPath = './libriphone'\n",
        "if Current_Env['inKaggle'] == True:\n",
        "    commonPath = '/kaggle/working/libriphone'\n",
        "\n",
        "filePath = commonPath + '/feat/train/103-1240-0015.pt';\n",
        "\n",
        "if os.path.exists(filePath) == False:\n",
        "    if Current_Env['inKaggle'] or Current_Env['inColab']:\n",
        "        !pip install --upgrade gdown\n",
        "        # Main link\n",
        "        # !gdown --id '1N1eVIDe9hKM5uiNRGmifBlwSDGiVXPJe' --output libriphone.zip\n",
        "        !gdown --id '1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1' --output libriphone.zip\n",
        "\n",
        "        !unzip -q libriphone.zip\n",
        "        !ls libriphone\n",
        "    elif Current_Env['inLocal']:\n",
        "        raise Exception('本地环境中文件不存在，需要重新下载，地址：https://www.kaggle.com/c/ml2023spring-hw2/data')\n",
        "    else:\n",
        "        raise Exception('获取文件失败，无法判断当前运行环境，也无法找到文件路径，需要重新下载，地址：https://www.kaggle.com/c/ml2023spring-hw2/data')\n",
        "else:\n",
        "    print('Data File already exist.Skip!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq9QdRGlNYZM"
      },
      "source": [
        "# Playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": [],
        "id": "Wox6BLnFNYZM"
      },
      "outputs": [],
      "source": [
        "# a = torch.load('./libriphone/feat/train/103-1240-0015.pt')\n",
        "# print(len(a))\n",
        "# print(len(a[0]))\n",
        "# print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pADUiYODJE1O"
      },
      "source": [
        "# Some Utility Functions\n",
        "**Fixes random number generator seeds for reproducibility.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BsZKgBZQJjaE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def same_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IJjLT8em-y9G",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def load_feat(path):\n",
        "    feat = torch.load(path)\n",
        "    return feat\n",
        "\n",
        "\n",
        "def shift(x, n):\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1  # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n)\n",
        "    x = x.view(seq_len, concat_n, feature_dim).permute(\n",
        "        1, 0, 2)  # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid+1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n",
        "    class_num = 41  # NOTE: pre-computed, should not need change\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        mode = 'train'\n",
        "    elif split == 'test':\n",
        "        mode = 'test'\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode == 'train':\n",
        "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(\n",
        "            phone_path, 'train_split.txt')).readlines()\n",
        "        random.seed(random_seed)\n",
        "        random.shuffle(usage_list)\n",
        "        train_len = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
        "\n",
        "    elif mode == 'test':\n",
        "        usage_list = open(os.path.join(\n",
        "            phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "    usage_list = [line.strip('\\n') for line in usage_list]\n",
        "    print('[Dataset] - # phone classes: ' + str(class_num) +\n",
        "          ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "    max_len = 3000000\n",
        "    X = torch.empty(max_len, 39 * concat_nframes)\n",
        "    if mode == 'train':\n",
        "        y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "    idx = 0\n",
        "    for i, fname in tqdm(enumerate(usage_list)):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "        cur_len = len(feat)\n",
        "        feat = concat_feat(feat, concat_nframes)\n",
        "        if mode == 'train':\n",
        "            label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "        X[idx: idx + cur_len, :] = feat\n",
        "        if mode == 'train':\n",
        "            y[idx: idx + cur_len] = label\n",
        "\n",
        "        idx += cur_len\n",
        "\n",
        "    X = X[:idx, :]\n",
        "    if mode == 'train':\n",
        "        y = y[:idx]\n",
        "\n",
        "    print(f'[INFO] {split} set')\n",
        "    print(X.shape)\n",
        "    if mode == 'train':\n",
        "        print(y.shape)\n",
        "        return X, y\n",
        "    else:\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Fjf5EcmJtf4e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "# Model\n",
        "Feel free to modify the structure of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Bg-GRd7ywdrL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, dropout_p):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # TODO: apply batch normalization and dropout for strong baseline.\n",
        "        # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
        "        #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256, dropout_p=0.5):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock(input_dim, hidden_dim, dropout_p),\n",
        "            *[BasicBlock(hidden_dim, hidden_dim, dropout_p)\n",
        "              for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlIq8JeqvvHC"
      },
      "source": [
        "# Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iIHn79Iav1ri",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# data prarameters\n",
        "# TODO: change the value of \"concat_nframes\" for medium baseline\n",
        "# the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "concat_nframes = 21\n",
        "# the ratio of data used for training, the rest will be used for validation\n",
        "train_ratio = 0.75\n",
        "\n",
        "# training parameters\n",
        "seed = 19871201          # random seed\n",
        "batch_size = 512        # batch size\n",
        "num_epoch = 60         # the number of training epoch\n",
        "learning_rate = 1e-3      # learning rate\n",
        "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
        "\n",
        "# model parameters\n",
        "# TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
        "# the input dim of the model, you should not change the value\n",
        "input_dim = 39 * concat_nframes\n",
        "hidden_layers = 2        # the number of hidden layers\n",
        "hidden_dim = 1750           # the hidden dim\n",
        "dropout_p = 0.75\n",
        "\n",
        "# env related\n",
        "commonPath = './libriphone'\n",
        "if Current_Env['inKaggle'] is True:\n",
        "    commonPath = '/kaggle/working/libriphone'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIUFRgG5yoDn"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "c1zI3v5jyrDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f09131-3840-4877-d46e-ad4e12766865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n",
            "[Dataset] - # phone classes: 41, number of utterances for train: 2571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2571it [00:11, 227.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] train set\n",
            "torch.Size([1580384, 819])\n",
            "torch.Size([1580384])\n",
            "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "858it [00:03, 273.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] val set\n",
            "torch.Size([536410, 819])\n",
            "torch.Size([536410])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "same_seeds(seed)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# preprocess data\n",
        "train_X, train_y = preprocess_data(split='train', feat_dir=commonPath + '/feat', phone_path=commonPath,\n",
        "                                   concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "val_X, val_y = preprocess_data(split='val', feat_dir=commonPath + '/feat', phone_path=commonPath,\n",
        "                               concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "\n",
        "# get dataset\n",
        "train_set = LibriDataset(train_X, train_y)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# get dataloader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwWH1KIqzxEr"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g612A7BaNYZN"
      },
      "source": [
        "## 测试默认配置下,各显卡的表现\n",
        "- 本地显卡：168秒\n",
        "- Kaggle: T100 239秒\n",
        "- Colab: 200秒以上\n",
        "\n",
        "结论：本地显卡>Kaggle>Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CdMWsBs7zzNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d84fbae-4c02-4bda-8461-c326198b53d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.14it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 166.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/060] Train Acc: 0.62484 Loss: 1.20766 | Val Acc: 0.67166 loss: 1.04612\n",
            "saving model with acc 0.67166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.19it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 138.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[002/060] Train Acc: 0.68932 Loss: 0.97607 | Val Acc: 0.69564 loss: 0.97056\n",
            "saving model with acc 0.69564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.33it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 159.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[003/060] Train Acc: 0.71913 Loss: 0.87109 | Val Acc: 0.70765 loss: 0.93709\n",
            "saving model with acc 0.70765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.93it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 156.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[004/060] Train Acc: 0.74065 Loss: 0.79354 | Val Acc: 0.71541 loss: 0.91781\n",
            "saving model with acc 0.71541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.00it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 140.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[005/060] Train Acc: 0.75896 Loss: 0.73096 | Val Acc: 0.71732 loss: 0.91987\n",
            "saving model with acc 0.71732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.79it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 172.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[006/060] Train Acc: 0.77414 Loss: 0.67800 | Val Acc: 0.72000 loss: 0.92493\n",
            "saving model with acc 0.72000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.93it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 143.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[007/060] Train Acc: 0.78688 Loss: 0.63357 | Val Acc: 0.72065 loss: 0.93237\n",
            "saving model with acc 0.72065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.59it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 160.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[008/060] Train Acc: 0.79790 Loss: 0.59706 | Val Acc: 0.72086 loss: 0.94441\n",
            "saving model with acc 0.72086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.43it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 170.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[009/060] Train Acc: 0.80692 Loss: 0.56648 | Val Acc: 0.71944 loss: 0.95769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.10it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 141.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[010/060] Train Acc: 0.81508 Loss: 0.54059 | Val Acc: 0.72092 loss: 0.96359\n",
            "saving model with acc 0.72092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.93it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 170.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[011/060] Train Acc: 0.82232 Loss: 0.51797 | Val Acc: 0.72087 loss: 0.97151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.10it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 159.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[012/060] Train Acc: 0.82836 Loss: 0.49798 | Val Acc: 0.71917 loss: 0.99006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.52it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 139.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[013/060] Train Acc: 0.83376 Loss: 0.48154 | Val Acc: 0.72002 loss: 0.99776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.70it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 171.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[014/060] Train Acc: 0.83908 Loss: 0.46616 | Val Acc: 0.71995 loss: 1.00890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.99it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 142.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[015/060] Train Acc: 0.84336 Loss: 0.45210 | Val Acc: 0.71966 loss: 1.01775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.66it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 165.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[016/060] Train Acc: 0.84702 Loss: 0.44060 | Val Acc: 0.72090 loss: 1.02238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 77.16it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 155.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[017/060] Train Acc: 0.85106 Loss: 0.42847 | Val Acc: 0.71972 loss: 1.03863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.32it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 139.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[018/060] Train Acc: 0.85442 Loss: 0.41820 | Val Acc: 0.71985 loss: 1.03895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.76it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 166.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[019/060] Train Acc: 0.85746 Loss: 0.40948 | Val Acc: 0.71982 loss: 1.05456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.20it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 136.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[020/060] Train Acc: 0.86025 Loss: 0.40007 | Val Acc: 0.71922 loss: 1.05586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.54it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 169.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[021/060] Train Acc: 0.86307 Loss: 0.39277 | Val Acc: 0.71886 loss: 1.05178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.35it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 151.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[022/060] Train Acc: 0.86552 Loss: 0.38541 | Val Acc: 0.72022 loss: 1.07191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.06it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 147.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[023/060] Train Acc: 0.86778 Loss: 0.37845 | Val Acc: 0.71849 loss: 1.06998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.75it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 168.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[024/060] Train Acc: 0.87015 Loss: 0.37136 | Val Acc: 0.71987 loss: 1.07022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.88it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 142.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[025/060] Train Acc: 0.87162 Loss: 0.36717 | Val Acc: 0.71874 loss: 1.06975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.92it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 169.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[026/060] Train Acc: 0.87380 Loss: 0.36016 | Val Acc: 0.71926 loss: 1.08220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.36it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 167.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[027/060] Train Acc: 0.87580 Loss: 0.35562 | Val Acc: 0.71949 loss: 1.08606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.34it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 142.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[028/060] Train Acc: 0.87743 Loss: 0.35005 | Val Acc: 0.71985 loss: 1.08800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.16it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 171.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[029/060] Train Acc: 0.87921 Loss: 0.34585 | Val Acc: 0.71891 loss: 1.09638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.54it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 153.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[030/060] Train Acc: 0.88036 Loss: 0.34191 | Val Acc: 0.71947 loss: 1.10014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.74it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 146.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[031/060] Train Acc: 0.88174 Loss: 0.33802 | Val Acc: 0.71850 loss: 1.11593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.37it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 171.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[032/060] Train Acc: 0.88336 Loss: 0.33310 | Val Acc: 0.72012 loss: 1.11655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.31it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 145.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[033/060] Train Acc: 0.88539 Loss: 0.32811 | Val Acc: 0.71953 loss: 1.11779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.23it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 158.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[034/060] Train Acc: 0.88602 Loss: 0.32515 | Val Acc: 0.71956 loss: 1.12168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.28it/s]\n",
            "100%|██████████| 1048/1048 [00:05<00:00, 174.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[035/060] Train Acc: 0.88714 Loss: 0.32269 | Val Acc: 0.72009 loss: 1.12476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.22it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 142.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[036/060] Train Acc: 0.88826 Loss: 0.31916 | Val Acc: 0.71856 loss: 1.12352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.29it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 169.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[037/060] Train Acc: 0.88940 Loss: 0.31525 | Val Acc: 0.71939 loss: 1.11628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.69it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 157.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[038/060] Train Acc: 0.89030 Loss: 0.31290 | Val Acc: 0.71956 loss: 1.12406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.58it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 141.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[039/060] Train Acc: 0.89156 Loss: 0.30974 | Val Acc: 0.72003 loss: 1.13734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.18it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 172.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[040/060] Train Acc: 0.89260 Loss: 0.30623 | Val Acc: 0.71919 loss: 1.14911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.12it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 146.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[041/060] Train Acc: 0.89368 Loss: 0.30315 | Val Acc: 0.71927 loss: 1.13751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.54it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 153.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[042/060] Train Acc: 0.89433 Loss: 0.30082 | Val Acc: 0.71899 loss: 1.13219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.17it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 172.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[043/060] Train Acc: 0.89544 Loss: 0.29837 | Val Acc: 0.72053 loss: 1.14520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.49it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 143.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[044/060] Train Acc: 0.89617 Loss: 0.29593 | Val Acc: 0.71869 loss: 1.14357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.52it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 164.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[045/060] Train Acc: 0.89669 Loss: 0.29436 | Val Acc: 0.71813 loss: 1.14221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.45it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 166.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[046/060] Train Acc: 0.89775 Loss: 0.29100 | Val Acc: 0.71978 loss: 1.14707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.33it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 142.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[047/060] Train Acc: 0.89860 Loss: 0.28997 | Val Acc: 0.72013 loss: 1.16399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.14it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 169.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[048/060] Train Acc: 0.89947 Loss: 0.28660 | Val Acc: 0.71835 loss: 1.15801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.35it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 159.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[049/060] Train Acc: 0.90038 Loss: 0.28470 | Val Acc: 0.71961 loss: 1.16089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.67it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 141.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[050/060] Train Acc: 0.90092 Loss: 0.28245 | Val Acc: 0.71894 loss: 1.16864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.35it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 172.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[051/060] Train Acc: 0.90140 Loss: 0.28065 | Val Acc: 0.71833 loss: 1.16985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.47it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 142.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[052/060] Train Acc: 0.90218 Loss: 0.27880 | Val Acc: 0.71918 loss: 1.16387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.57it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 162.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[053/060] Train Acc: 0.90218 Loss: 0.27820 | Val Acc: 0.71926 loss: 1.17747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.65it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 170.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[054/060] Train Acc: 0.90369 Loss: 0.27520 | Val Acc: 0.71989 loss: 1.16114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.40it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 145.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[055/060] Train Acc: 0.90410 Loss: 0.27354 | Val Acc: 0.71931 loss: 1.17944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 78.08it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 170.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[056/060] Train Acc: 0.90452 Loss: 0.27153 | Val Acc: 0.71915 loss: 1.18473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.74it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 164.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[057/060] Train Acc: 0.90565 Loss: 0.26926 | Val Acc: 0.71968 loss: 1.16871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 77.01it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 137.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[058/060] Train Acc: 0.90597 Loss: 0.26825 | Val Acc: 0.72028 loss: 1.17029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:40<00:00, 76.88it/s]\n",
            "100%|██████████| 1048/1048 [00:06<00:00, 171.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[059/060] Train Acc: 0.90629 Loss: 0.26760 | Val Acc: 0.71933 loss: 1.16875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3087/3087 [00:39<00:00, 77.34it/s]\n",
            "100%|██████████| 1048/1048 [00:07<00:00, 141.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[060/060] Train Acc: 0.90703 Loss: 0.26516 | Val Acc: 0.71961 loss: 1.18399\n",
            "total train start at: 2023-11-17 07:43:43.990926\n",
            "concat_nframes: 21 ,num_epoch: 60 ,learning_rate: 0.001 ,Dropout:\n",
            "total train cost:  46 minutes 23 seconds (total seconds: 2783 s).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# log train start time\n",
        "starttime = datetime.datetime.now()\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers,\n",
        "                   hidden_dim=hidden_dim, dropout_p=dropout_p).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train()  # set the model to training mode\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # get the index of the class with the highest probability\n",
        "        _, train_pred = torch.max(outputs, 1)\n",
        "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # validation\n",
        "    model.eval()  # set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(val_loader)):\n",
        "            features, labels = batch\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(features)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, val_pred = torch.max(outputs, 1)\n",
        "            # get the index of the class with the highest probability\n",
        "            val_acc += (val_pred.cpu() == labels.cpu()).sum().item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n",
        "\n",
        "    # if the model improves, save a checkpoint at this epoch\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n",
        "\n",
        "# log train cost time\n",
        "print('total train start at:', starttime)\n",
        "print('concat_nframes:', concat_nframes, ',num_epoch:',\n",
        "      num_epoch, ',learning_rate:', learning_rate, ',Dropout:')\n",
        "totalseconds = (datetime.datetime.now()-starttime).seconds\n",
        "print('total train cost: ', math.floor(totalseconds/60),\n",
        "      'minutes', totalseconds % 60, 'seconds (total seconds:', totalseconds, 's).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ab33MxosWLmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4716ef9f-6fab-47a0-e12e-935674447c7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "del train_set, val_set\n",
        "del train_loader, val_loader\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "# Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOG1Ou0PGrhc",
        "outputId": "c6352ae2-57f7-493f-e568-fd27f2897724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "857it [00:03, 239.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] test set\n",
            "torch.Size([527364, 819])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat',\n",
        "                         phone_path='./libriphone', concat_nframes=concat_nframes)\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay0Fu8Ovkdad",
        "outputId": "6aed84bf-b19c-410b-e27f-6f2d0115248b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load model\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers,\n",
        "                   hidden_dim=hidden_dim, dropout_p=dropout_p).to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84HU5GGjPqR0",
        "outputId": "2d18726a-e2c0-412e-ee02-f0bf4d41e03b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1031/1031 [00:05<00:00, 193.31it/s]\n"
          ]
        }
      ],
      "source": [
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        features = features.to(device)\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        # get the index of the class with the highest probability\n",
        "        _, test_pred = torch.max(outputs, 1)\n",
        "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyZqy40Prz0v"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}