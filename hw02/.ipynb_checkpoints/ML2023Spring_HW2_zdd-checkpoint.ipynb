{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYlaRwNu7ojq"
   },
   "source": [
    "# **Homework 2: Phoneme Classification**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7DRC5V7_8A5"
   },
   "source": [
    "Objectives:\n",
    "* Solve a classification problem with deep neural networks (DNNs).\n",
    "* Understand recursive neural networks (RNNs).\n",
    "\n",
    "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 17 17:27:35 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.13                 Driver Version: 537.13       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   45C    P5               6W / 114W |   1706MiB /  8188MiB |     16%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     11216      C   C:\\ProgramData\\anaconda3\\python.exe       N/A      |\n",
      "|    0   N/A  N/A     19172    C+G   ...ns\\Software\\Current\\LogiOverlay.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free memory: param already deleted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3923"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取当前工作环境\n",
    "def KaggleColabLocal():\n",
    "    env = dict(\n",
    "        inKaggle=False,\n",
    "        inColab=False,\n",
    "        inLocal=False\n",
    "    )\n",
    "\n",
    "    # 检查是否在Kaggle环境中\n",
    "    if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ and os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive':\n",
    "        # print(\"在Kaggle环境中运行\")\n",
    "        env['inKaggle'] = True\n",
    "    # 检查是否在Colab环境中\n",
    "    elif 'google.colab' in str(get_ipython()):\n",
    "        # print(\"在Colab环境中运行\")\n",
    "        env['inColab'] = True\n",
    "    # 检查是否在本地JupyterLab环境中\n",
    "    elif 'JPY_PARENT_PID' in os.environ:\n",
    "        # print(\"在本地JupyterLab环境中运行\")\n",
    "        env['inLocal'] = True\n",
    "    else:\n",
    "        print(\"在其他环境中运行\")\n",
    "    return env\n",
    "\n",
    "\n",
    "KaggleColabLocal()\n",
    "\n",
    "try:\n",
    "    del train_set,val_set\n",
    "    del train_loader,val_loader\n",
    "except:\n",
    "    print(\"free memory: param already deleted.\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVUGfWTo7_Oj",
    "tags": []
   },
   "source": [
    "# Download Data\n",
    "Download data from google drive, then unzip it.\n",
    "\n",
    "You should have\n",
    "- `libriphone/train_split.txt`: training metadata\n",
    "- `libriphone/train_labels`: training labels\n",
    "- `libriphone/test_split.txt`: testing metadata\n",
    "- `libriphone/feat/train/*.pt`: training feature\n",
    "- `libriphone/feat/test/*.pt`:  testing feature\n",
    "\n",
    "after running the following block.\n",
    "\n",
    "> **Notes: if the google drive link is dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2023spring-hw2/data) and upload it to the workspace.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "OzkiMEcC3Foq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data File already exist.Skip!\n"
     ]
    }
   ],
   "source": [
    "Current_Env = KaggleColabLocal() # 获取当前环境\n",
    "\n",
    "# 如果文件已经下载，那不用重新下载文件\n",
    "commonPath = './libriphone'\n",
    "if Current_Env['inKaggle'] == True:\n",
    "    commonPath = '/kaggle/working/libriphone'\n",
    "\n",
    "filePath = commonPath + '/feat/train/103-1240-0015.pt';\n",
    "\n",
    "if os.path.exists(filePath) == False:\n",
    "    if Current_Env['inKaggle'] or Current_Env['inColab']:\n",
    "        !pip install --upgrade gdown\n",
    "        # Main link\n",
    "        # !gdown --id '1N1eVIDe9hKM5uiNRGmifBlwSDGiVXPJe' --output libriphone.zip\n",
    "        !gdown --id '1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1' --output libriphone.zip\n",
    "\n",
    "        !unzip -q libriphone.zip\n",
    "        !ls libriphone\n",
    "    elif Current_Env['inLocal']:\n",
    "        raise Exception('本地环境中文件不存在，需要重新下载，地址：https://www.kaggle.com/c/ml2023spring-hw2/data')\n",
    "    else:\n",
    "        raise Exception('获取文件失败，无法判断当前运行环境，也无法找到文件路径，需要重新下载，地址：https://www.kaggle.com/c/ml2023spring-hw2/data')\n",
    "else:\n",
    "    print('Data File already exist.Skip!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = torch.load('./libriphone/feat/train/103-1240-0015.pt')\n",
    "# print(len(a))\n",
    "# print(len(a[0]))\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pADUiYODJE1O"
   },
   "source": [
    "# Some Utility Functions\n",
    "**Fixes random number generator seeds for reproducibility.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "BsZKgBZQJjaE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L_4anls8Drv"
   },
   "source": [
    "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
    "\n",
    "A phoneme may span several frames and is dependent to past and future frames. \\\n",
    "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
    "\n",
    "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "IJjLT8em-y9G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_feat(path):\n",
    "    feat = torch.load(path)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def shift(x, n):\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "\n",
    "\n",
    "def concat_feat(x, concat_n):\n",
    "    assert concat_n % 2 == 1  # n must be odd\n",
    "    if concat_n < 2:\n",
    "        return x\n",
    "    seq_len, feature_dim = x.size(0), x.size(1)\n",
    "    x = x.repeat(1, concat_n)\n",
    "    x = x.view(seq_len, concat_n, feature_dim).permute(\n",
    "        1, 0, 2)  # concat_n, seq_len, feature_dim\n",
    "    mid = (concat_n // 2)\n",
    "    for r_idx in range(1, mid+1):\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "\n",
    "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
    "\n",
    "\n",
    "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n",
    "    class_num = 41  # NOTE: pre-computed, should not need change\n",
    "\n",
    "    if split == 'train' or split == 'val':\n",
    "        mode = 'train'\n",
    "    elif split == 'test':\n",
    "        mode = 'test'\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            'Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
    "\n",
    "    label_dict = {}\n",
    "    if mode == 'train':\n",
    "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
    "            line = line.strip('\\n').split(' ')\n",
    "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
    "\n",
    "        # split training and validation data\n",
    "        usage_list = open(os.path.join(\n",
    "            phone_path, 'train_split.txt')).readlines()\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(usage_list)\n",
    "        train_len = int(len(usage_list) * train_ratio)\n",
    "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
    "\n",
    "    elif mode == 'test':\n",
    "        usage_list = open(os.path.join(\n",
    "            phone_path, 'test_split.txt')).readlines()\n",
    "\n",
    "    usage_list = [line.strip('\\n') for line in usage_list]\n",
    "    print('[Dataset] - # phone classes: ' + str(class_num) +\n",
    "          ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
    "\n",
    "    max_len = 3000000\n",
    "    X = torch.empty(max_len, 39 * concat_nframes)\n",
    "    if mode == 'train':\n",
    "        y = torch.empty(max_len, dtype=torch.long)\n",
    "\n",
    "    idx = 0\n",
    "    for i, fname in tqdm(enumerate(usage_list)):\n",
    "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
    "        cur_len = len(feat)\n",
    "        feat = concat_feat(feat, concat_nframes)\n",
    "        if mode == 'train':\n",
    "            label = torch.LongTensor(label_dict[fname])\n",
    "\n",
    "        X[idx: idx + cur_len, :] = feat\n",
    "        if mode == 'train':\n",
    "            y[idx: idx + cur_len] = label\n",
    "\n",
    "        idx += cur_len\n",
    "\n",
    "    X = X[:idx, :]\n",
    "    if mode == 'train':\n",
    "        y = y[:idx]\n",
    "\n",
    "    print(f'[INFO] {split} set')\n",
    "    print(X.shape)\n",
    "    if mode == 'train':\n",
    "        print(y.shape)\n",
    "        return X, y\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "us5XW_x6udZQ"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "Fjf5EcmJtf4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        if y is not None:\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRqKNvNZwe3V"
   },
   "source": [
    "# Model\n",
    "Feel free to modify the structure of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "Bg-GRd7ywdrL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_p):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # TODO: apply batch normalization and dropout for strong baseline.\n",
    "        # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
    "        #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256, dropout_p=0.5):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            BasicBlock(input_dim, hidden_dim, dropout_p),\n",
    "            *[BasicBlock(hidden_dim, hidden_dim, dropout_p)\n",
    "              for _ in range(hidden_layers)],\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlIq8JeqvvHC"
   },
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "iIHn79Iav1ri",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data prarameters\n",
    "# TODO: change the value of \"concat_nframes\" for medium baseline\n",
    "# the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
    "concat_nframes = 21\n",
    "# the ratio of data used for training, the rest will be used for validation\n",
    "train_ratio = 0.75\n",
    "\n",
    "# training parameters\n",
    "seed = 19871201          # random seed\n",
    "batch_size = 512        # batch size\n",
    "num_epoch = 300         # the number of training epoch\n",
    "learning_rate = 1e-3      # learning rate\n",
    "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
    "\n",
    "# model parameters\n",
    "# TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
    "# the input dim of the model, you should not change the value\n",
    "input_dim = 39 * concat_nframes\n",
    "hidden_layers = 2        # the number of hidden layers\n",
    "hidden_dim = 1750           # the hidden dim\n",
    "dropout_p = 0.5\n",
    "\n",
    "# env related\n",
    "commonPath = './libriphone'\n",
    "if Current_Env['inKaggle'] is True:\n",
    "    commonPath = '/kaggle/working/libriphone'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIUFRgG5yoDn"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "c1zI3v5jyrDn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "[Dataset] - # phone classes: 41, number of utterances for train: 2571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2571it [00:11, 226.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([1580384, 819])\n",
      "torch.Size([1580384])\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "858it [00:03, 214.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([536410, 819])\n",
      "torch.Size([536410])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "same_seeds(seed)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE: {device}')\n",
    "\n",
    "# preprocess data\n",
    "train_X, train_y = preprocess_data(split='train', feat_dir=commonPath + '/feat', phone_path=commonPath,\n",
    "                                   concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
    "val_X, val_y = preprocess_data(split='val', feat_dir=commonPath + '/feat', phone_path=commonPath,\n",
    "                               concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
    "\n",
    "# get dataset\n",
    "train_set = LibriDataset(train_X, train_y)\n",
    "val_set = LibriDataset(val_X, val_y)\n",
    "\n",
    "# remove raw feature to save memory\n",
    "del train_X, train_y, val_X, val_y\n",
    "gc.collect()\n",
    "\n",
    "# get dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwWH1KIqzxEr"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试默认配置下,各显卡的表现\n",
    "- 本地显卡：168秒\n",
    "- Kaggle: T100 239秒\n",
    "- Colab: 200秒以上\n",
    "\n",
    "结论：本地显卡>Kaggle>Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "CdMWsBs7zzNs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:38<00:00, 79.52it/s] \n",
      "100%|██████████| 1048/1048 [00:07<00:00, 145.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/060] Train Acc: 0.57672 Loss: 1.38555 | Val Acc: 0.64819 loss: 1.12797\n",
      "saving model with acc 0.64819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:37<00:00, 81.41it/s]\n",
      "100%|██████████| 1048/1048 [00:06<00:00, 153.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/060] Train Acc: 0.63254 Loss: 1.17914 | Val Acc: 0.67381 loss: 1.04029\n",
      "saving model with acc 0.67381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:37<00:00, 82.44it/s]\n",
      "100%|██████████| 1048/1048 [00:06<00:00, 153.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003/060] Train Acc: 0.65332 Loss: 1.10234 | Val Acc: 0.68712 loss: 0.99449\n",
      "saving model with acc 0.68712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:37<00:00, 81.67it/s]\n",
      "100%|██████████| 1048/1048 [00:06<00:00, 166.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004/060] Train Acc: 0.66748 Loss: 1.05205 | Val Acc: 0.69782 loss: 0.95725\n",
      "saving model with acc 0.69782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:38<00:00, 80.80it/s]\n",
      "100%|██████████| 1048/1048 [00:10<00:00, 101.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005/060] Train Acc: 0.67841 Loss: 1.01397 | Val Acc: 0.70458 loss: 0.93802\n",
      "saving model with acc 0.70458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:37<00:00, 82.66it/s]\n",
      "100%|██████████| 1048/1048 [00:06<00:00, 168.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[006/060] Train Acc: 0.68603 Loss: 0.98637 | Val Acc: 0.70866 loss: 0.92332\n",
      "saving model with acc 0.70866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:37<00:00, 83.09it/s]\n",
      "100%|██████████| 1048/1048 [00:06<00:00, 155.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[007/060] Train Acc: 0.69219 Loss: 0.96489 | Val Acc: 0.71308 loss: 0.90736\n",
      "saving model with acc 0.71308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:32<00:00, 93.73it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 181.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[008/060] Train Acc: 0.69746 Loss: 0.94508 | Val Acc: 0.71658 loss: 0.89646\n",
      "saving model with acc 0.71658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:32<00:00, 94.61it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 186.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[009/060] Train Acc: 0.70194 Loss: 0.92926 | Val Acc: 0.71790 loss: 0.89354\n",
      "saving model with acc 0.71790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:32<00:00, 94.78it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 194.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010/060] Train Acc: 0.70603 Loss: 0.91483 | Val Acc: 0.71934 loss: 0.88530\n",
      "saving model with acc 0.71934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:32<00:00, 95.05it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 185.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[011/060] Train Acc: 0.70970 Loss: 0.90230 | Val Acc: 0.72229 loss: 0.87826\n",
      "saving model with acc 0.72229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 97.67it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 207.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[012/060] Train Acc: 0.71257 Loss: 0.89165 | Val Acc: 0.72416 loss: 0.87387\n",
      "saving model with acc 0.72416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.87it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 198.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[013/060] Train Acc: 0.71507 Loss: 0.88115 | Val Acc: 0.72503 loss: 0.87078\n",
      "saving model with acc 0.72503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.68it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 191.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[014/060] Train Acc: 0.71802 Loss: 0.87161 | Val Acc: 0.72592 loss: 0.86562\n",
      "saving model with acc 0.72592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.08it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 190.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[015/060] Train Acc: 0.72050 Loss: 0.86332 | Val Acc: 0.72718 loss: 0.86141\n",
      "saving model with acc 0.72718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.75it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 205.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[016/060] Train Acc: 0.72244 Loss: 0.85583 | Val Acc: 0.72878 loss: 0.85978\n",
      "saving model with acc 0.72878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.38it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 201.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[017/060] Train Acc: 0.72470 Loss: 0.84766 | Val Acc: 0.72919 loss: 0.85663\n",
      "saving model with acc 0.72919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 102.32it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 204.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[018/060] Train Acc: 0.72648 Loss: 0.84145 | Val Acc: 0.73079 loss: 0.85387\n",
      "saving model with acc 0.73079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.09it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 202.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[019/060] Train Acc: 0.72820 Loss: 0.83518 | Val Acc: 0.73127 loss: 0.85310\n",
      "saving model with acc 0.73127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.16it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 206.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020/060] Train Acc: 0.72983 Loss: 0.82864 | Val Acc: 0.73127 loss: 0.85140\n",
      "saving model with acc 0.73127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.05it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 199.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[021/060] Train Acc: 0.73208 Loss: 0.82238 | Val Acc: 0.73252 loss: 0.84649\n",
      "saving model with acc 0.73252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.06it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 203.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[022/060] Train Acc: 0.73359 Loss: 0.81675 | Val Acc: 0.73323 loss: 0.84688\n",
      "saving model with acc 0.73323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.71it/s] \n",
      "100%|██████████| 1048/1048 [00:04<00:00, 210.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[023/060] Train Acc: 0.73507 Loss: 0.81181 | Val Acc: 0.73310 loss: 0.84535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 101.09it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 209.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[024/060] Train Acc: 0.73576 Loss: 0.80845 | Val Acc: 0.73484 loss: 0.84150\n",
      "saving model with acc 0.73484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.84it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 197.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[025/060] Train Acc: 0.73710 Loss: 0.80366 | Val Acc: 0.73492 loss: 0.83959\n",
      "saving model with acc 0.73492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.63it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 195.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[026/060] Train Acc: 0.73871 Loss: 0.79838 | Val Acc: 0.73568 loss: 0.83935\n",
      "saving model with acc 0.73568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.51it/s] \n",
      "100%|██████████| 1048/1048 [00:04<00:00, 209.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[027/060] Train Acc: 0.74005 Loss: 0.79407 | Val Acc: 0.73447 loss: 0.83952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.94it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 197.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[028/060] Train Acc: 0.74107 Loss: 0.78982 | Val Acc: 0.73656 loss: 0.83565\n",
      "saving model with acc 0.73656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.05it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 191.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[029/060] Train Acc: 0.74171 Loss: 0.78694 | Val Acc: 0.73593 loss: 0.83820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.42it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 203.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[030/060] Train Acc: 0.74285 Loss: 0.78324 | Val Acc: 0.73616 loss: 0.83689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 101.26it/s]\n",
      "100%|██████████| 1048/1048 [00:04<00:00, 214.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[031/060] Train Acc: 0.74411 Loss: 0.77930 | Val Acc: 0.73753 loss: 0.83629\n",
      "saving model with acc 0.73753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.70it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 196.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[032/060] Train Acc: 0.74519 Loss: 0.77574 | Val Acc: 0.73827 loss: 0.83528\n",
      "saving model with acc 0.73827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.67it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 200.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[033/060] Train Acc: 0.74646 Loss: 0.77193 | Val Acc: 0.73752 loss: 0.83472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.43it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 199.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[034/060] Train Acc: 0.74679 Loss: 0.76893 | Val Acc: 0.73822 loss: 0.83387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.78it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 191.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[035/060] Train Acc: 0.74742 Loss: 0.76658 | Val Acc: 0.73874 loss: 0.83340\n",
      "saving model with acc 0.73874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.55it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 188.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[036/060] Train Acc: 0.74815 Loss: 0.76310 | Val Acc: 0.73827 loss: 0.83382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.43it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 201.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[037/060] Train Acc: 0.74943 Loss: 0.75986 | Val Acc: 0.73826 loss: 0.83149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 101.77it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 202.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[038/060] Train Acc: 0.75023 Loss: 0.75741 | Val Acc: 0.73975 loss: 0.83035\n",
      "saving model with acc 0.73975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.76it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 204.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[039/060] Train Acc: 0.75043 Loss: 0.75601 | Val Acc: 0.74002 loss: 0.83040\n",
      "saving model with acc 0.74002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.87it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 191.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[040/060] Train Acc: 0.75178 Loss: 0.75263 | Val Acc: 0.73939 loss: 0.83225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.00it/s]\n",
      "100%|██████████| 1048/1048 [00:04<00:00, 216.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[041/060] Train Acc: 0.75216 Loss: 0.75001 | Val Acc: 0.73990 loss: 0.83162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.72it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 198.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[042/060] Train Acc: 0.75279 Loss: 0.74784 | Val Acc: 0.74030 loss: 0.82969\n",
      "saving model with acc 0.74030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.31it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 195.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[043/060] Train Acc: 0.75346 Loss: 0.74585 | Val Acc: 0.74092 loss: 0.82969\n",
      "saving model with acc 0.74092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.06it/s] \n",
      "100%|██████████| 1048/1048 [00:04<00:00, 216.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[044/060] Train Acc: 0.75416 Loss: 0.74315 | Val Acc: 0.73984 loss: 0.82932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.90it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 190.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[045/060] Train Acc: 0.75485 Loss: 0.74093 | Val Acc: 0.74032 loss: 0.83099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.96it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 193.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[046/060] Train Acc: 0.75529 Loss: 0.73952 | Val Acc: 0.74018 loss: 0.82741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.51it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 197.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[047/060] Train Acc: 0.75619 Loss: 0.73650 | Val Acc: 0.74072 loss: 0.82957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.68it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 192.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[048/060] Train Acc: 0.75703 Loss: 0.73440 | Val Acc: 0.74110 loss: 0.82690\n",
      "saving model with acc 0.74110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.10it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 197.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[049/060] Train Acc: 0.75707 Loss: 0.73215 | Val Acc: 0.74137 loss: 0.82825\n",
      "saving model with acc 0.74137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.28it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 203.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[050/060] Train Acc: 0.75730 Loss: 0.73088 | Val Acc: 0.74120 loss: 0.82691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 101.31it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 200.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[051/060] Train Acc: 0.75808 Loss: 0.72936 | Val Acc: 0.74162 loss: 0.82553\n",
      "saving model with acc 0.74162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.98it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 208.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[052/060] Train Acc: 0.75870 Loss: 0.72713 | Val Acc: 0.74110 loss: 0.82875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.20it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 196.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[053/060] Train Acc: 0.75942 Loss: 0.72524 | Val Acc: 0.74119 loss: 0.83122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.89it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 195.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[054/060] Train Acc: 0.75975 Loss: 0.72330 | Val Acc: 0.74173 loss: 0.82867\n",
      "saving model with acc 0.74173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 100.59it/s]\n",
      "100%|██████████| 1048/1048 [00:05<00:00, 183.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[055/060] Train Acc: 0.76024 Loss: 0.72163 | Val Acc: 0.74152 loss: 0.82636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 99.60it/s] \n",
      "100%|██████████| 1048/1048 [00:04<00:00, 216.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[056/060] Train Acc: 0.76114 Loss: 0.71965 | Val Acc: 0.74229 loss: 0.82741\n",
      "saving model with acc 0.74229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:30<00:00, 101.76it/s]\n",
      "100%|██████████| 1048/1048 [00:04<00:00, 212.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[057/060] Train Acc: 0.76165 Loss: 0.71790 | Val Acc: 0.74211 loss: 0.82349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.47it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 202.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[058/060] Train Acc: 0.76214 Loss: 0.71546 | Val Acc: 0.74256 loss: 0.82449\n",
      "saving model with acc 0.74256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.10it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 183.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[059/060] Train Acc: 0.76216 Loss: 0.71556 | Val Acc: 0.74227 loss: 0.82523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.35it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 197.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[060/060] Train Acc: 0.76236 Loss: 0.71452 | Val Acc: 0.74229 loss: 0.82427\n",
      "total train start at: 2023-11-17 15:43:19.310420\n",
      "concat_nframes: 21 ,num_epoch: 60 ,learning_rate: 0.001 ,Dropout:\n",
      "total train cost:  37 minutes 21 seconds (total seconds: 2241 s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# log train start time\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# create model, define a loss function, and optimizer\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers,\n",
    "                   hidden_dim=hidden_dim, dropout_p=dropout_p).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epoch):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train()  # set the model to training mode\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        features, labels = batch\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # get the index of the class with the highest probability\n",
    "        _, train_pred = torch.max(outputs, 1)\n",
    "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(val_loader)):\n",
    "            features, labels = batch\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, val_pred = torch.max(outputs, 1)\n",
    "            # get the index of the class with the highest probability\n",
    "            val_acc += (val_pred.cpu() == labels.cpu()).sum().item()\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n",
    "\n",
    "    # if the model improves, save a checkpoint at this epoch\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n",
    "\n",
    "# log train cost time\n",
    "print('total train start at:', starttime)\n",
    "print('concat_nframes:', concat_nframes, ',num_epoch:',\n",
    "      num_epoch, ',learning_rate:', learning_rate, ',Dropout:')\n",
    "totalseconds = (datetime.datetime.now()-starttime).seconds\n",
    "print('total train cost: ', math.floor(totalseconds/60),\n",
    "      'minutes', totalseconds % 60, 'seconds (total seconds:', totalseconds, 's).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "ab33MxosWLmG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[265], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_set, val_set\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_loader, val_loader\n\u001b[0;32m      3\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "del train_set, val_set\n",
    "del train_loader, val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Hi7jTn3PX-m"
   },
   "source": [
    "# Testing\n",
    "Create a testing dataset, and load model from the saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "VOG1Ou0PGrhc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for test: 857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "857it [00:03, 239.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([527364, 819])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat',\n",
    "                         phone_path='./libriphone', concat_nframes=concat_nframes)\n",
    "test_set = LibriDataset(test_X, None)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "ay0Fu8Ovkdad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers,\n",
    "                   hidden_dim=hidden_dim, dropout_p=dropout_p).to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp-DV1p4r7Nz"
   },
   "source": [
    "Make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "84HU5GGjPqR0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1031/1031 [00:05<00:00, 193.31it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([], dtype=np.int32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        features = batch\n",
    "        features = features.to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "\n",
    "        # get the index of the class with the highest probability\n",
    "        _, test_pred = torch.max(outputs, 1)\n",
    "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyZqy40Prz0v"
   },
   "source": [
    "Write prediction to a CSV file.\n",
    "\n",
    "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuljYSPHcZir"
   },
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(pred):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
