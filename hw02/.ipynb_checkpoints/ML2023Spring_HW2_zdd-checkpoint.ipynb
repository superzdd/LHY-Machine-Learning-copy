{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYlaRwNu7ojq"
   },
   "source": [
    "# **Homework 2: Phoneme Classification**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7DRC5V7_8A5"
   },
   "source": [
    "Objectives:\n",
    "* Solve a classification problem with deep neural networks (DNNs).\n",
    "* Understand recursive neural networks (RNNs).\n",
    "\n",
    "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 17 15:25:44 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.13                 Driver Version: 537.13       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   42C    P5               5W / 120W |   1694MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     11216      C   C:\\ProgramData\\anaconda3\\python.exe       N/A      |\n",
      "|    0   N/A  N/A     19172    C+G   ...ns\\Software\\Current\\LogiOverlay.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free memory: param already deleted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取当前工作环境\n",
    "def KaggleColabLocal():\n",
    "    env = dict(\n",
    "        inKaggle=False,\n",
    "        inColab=False,\n",
    "        inLocal=False\n",
    "    )\n",
    "\n",
    "    # 检查是否在Kaggle环境中\n",
    "    if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ and os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive':\n",
    "        # print(\"在Kaggle环境中运行\")\n",
    "        env['inKaggle'] = True\n",
    "    # 检查是否在Colab环境中\n",
    "    elif 'google.colab' in str(get_ipython()):\n",
    "        # print(\"在Colab环境中运行\")\n",
    "        env['inColab'] = True\n",
    "    # 检查是否在本地JupyterLab环境中\n",
    "    elif 'JPY_PARENT_PID' in os.environ:\n",
    "        # print(\"在本地JupyterLab环境中运行\")\n",
    "        env['inLocal'] = True\n",
    "    else:\n",
    "        print(\"在其他环境中运行\")\n",
    "    return env\n",
    "\n",
    "\n",
    "KaggleColabLocal()\n",
    "\n",
    "try:\n",
    "    del train_set,val_set\n",
    "    del train_loader,val_loader\n",
    "except:\n",
    "    print(\"free memory: param already deleted.\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVUGfWTo7_Oj",
    "tags": []
   },
   "source": [
    "# Download Data\n",
    "Download data from google drive, then unzip it.\n",
    "\n",
    "You should have\n",
    "- `libriphone/train_split.txt`: training metadata\n",
    "- `libriphone/train_labels`: training labels\n",
    "- `libriphone/test_split.txt`: testing metadata\n",
    "- `libriphone/feat/train/*.pt`: training feature\n",
    "- `libriphone/feat/test/*.pt`:  testing feature\n",
    "\n",
    "after running the following block.\n",
    "\n",
    "> **Notes: if the google drive link is dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2023spring-hw2/data) and upload it to the workspace.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "OzkiMEcC3Foq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data File already exist.Skip!\n"
     ]
    }
   ],
   "source": [
    "Current_Env = KaggleColabLocal() # 获取当前环境\n",
    "\n",
    "# 如果文件已经下载，那不用重新下载文件\n",
    "commonPath = './libriphone'\n",
    "if Current_Env['inKaggle'] == True:\n",
    "    commonPath = '/kaggle/working/libriphone'\n",
    "\n",
    "filePath = commonPath + '/feat/train/103-1240-0015.pt';\n",
    "\n",
    "if os.path.exists(filePath) == False:\n",
    "    if Current_Env['inKaggle'] or Current_Env['inColab']:\n",
    "        !pip install --upgrade gdown\n",
    "        # Main link\n",
    "        # !gdown --id '1N1eVIDe9hKM5uiNRGmifBlwSDGiVXPJe' --output libriphone.zip\n",
    "        !gdown --id '1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1' --output libriphone.zip\n",
    "\n",
    "        !unzip -q libriphone.zip\n",
    "        !ls libriphone\n",
    "    elif Current_Env['inLocal']:\n",
    "        raise Exception('本地环境中文件不存在，需要重新下载，地址：https://www.kaggle.com/c/ml2023spring-hw2/data')\n",
    "    else:\n",
    "        raise Exception('获取文件失败，无法判断当前运行环境，也无法找到文件路径，需要重新下载，地址：https://www.kaggle.com/c/ml2023spring-hw2/data')\n",
    "else:\n",
    "    print('Data File already exist.Skip!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = torch.load('./libriphone/feat/train/103-1240-0015.pt')\n",
    "# print(len(a))\n",
    "# print(len(a[0]))\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pADUiYODJE1O"
   },
   "source": [
    "# Some Utility Functions\n",
    "**Fixes random number generator seeds for reproducibility.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "BsZKgBZQJjaE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_L_4anls8Drv"
   },
   "source": [
    "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
    "\n",
    "A phoneme may span several frames and is dependent to past and future frames. \\\n",
    "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
    "\n",
    "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "IJjLT8em-y9G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_feat(path):\n",
    "    feat = torch.load(path)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def shift(x, n):\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "\n",
    "\n",
    "def concat_feat(x, concat_n):\n",
    "    assert concat_n % 2 == 1  # n must be odd\n",
    "    if concat_n < 2:\n",
    "        return x\n",
    "    seq_len, feature_dim = x.size(0), x.size(1)\n",
    "    x = x.repeat(1, concat_n)\n",
    "    x = x.view(seq_len, concat_n, feature_dim).permute(\n",
    "        1, 0, 2)  # concat_n, seq_len, feature_dim\n",
    "    mid = (concat_n // 2)\n",
    "    for r_idx in range(1, mid+1):\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "\n",
    "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
    "\n",
    "\n",
    "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n",
    "    class_num = 41  # NOTE: pre-computed, should not need change\n",
    "\n",
    "    if split == 'train' or split == 'val':\n",
    "        mode = 'train'\n",
    "    elif split == 'test':\n",
    "        mode = 'test'\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            'Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
    "\n",
    "    label_dict = {}\n",
    "    if mode == 'train':\n",
    "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
    "            line = line.strip('\\n').split(' ')\n",
    "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
    "\n",
    "        # split training and validation data\n",
    "        usage_list = open(os.path.join(\n",
    "            phone_path, 'train_split.txt')).readlines()\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(usage_list)\n",
    "        train_len = int(len(usage_list) * train_ratio)\n",
    "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
    "\n",
    "    elif mode == 'test':\n",
    "        usage_list = open(os.path.join(\n",
    "            phone_path, 'test_split.txt')).readlines()\n",
    "\n",
    "    usage_list = [line.strip('\\n') for line in usage_list]\n",
    "    print('[Dataset] - # phone classes: ' + str(class_num) +\n",
    "          ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
    "\n",
    "    max_len = 3000000\n",
    "    X = torch.empty(max_len, 39 * concat_nframes)\n",
    "    if mode == 'train':\n",
    "        y = torch.empty(max_len, dtype=torch.long)\n",
    "\n",
    "    idx = 0\n",
    "    for i, fname in tqdm(enumerate(usage_list)):\n",
    "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
    "        cur_len = len(feat)\n",
    "        feat = concat_feat(feat, concat_nframes)\n",
    "        if mode == 'train':\n",
    "            label = torch.LongTensor(label_dict[fname])\n",
    "\n",
    "        X[idx: idx + cur_len, :] = feat\n",
    "        if mode == 'train':\n",
    "            y[idx: idx + cur_len] = label\n",
    "\n",
    "        idx += cur_len\n",
    "\n",
    "    X = X[:idx, :]\n",
    "    if mode == 'train':\n",
    "        y = y[:idx]\n",
    "\n",
    "    print(f'[INFO] {split} set')\n",
    "    print(X.shape)\n",
    "    if mode == 'train':\n",
    "        print(y.shape)\n",
    "        return X, y\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "us5XW_x6udZQ"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "Fjf5EcmJtf4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        if y is not None:\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRqKNvNZwe3V"
   },
   "source": [
    "# Model\n",
    "Feel free to modify the structure of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "Bg-GRd7ywdrL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_p):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # TODO: apply batch normalization and dropout for strong baseline.\n",
    "        # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
    "        #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256, dropout_p=0.5):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            BasicBlock(input_dim, hidden_dim, dropout_p),\n",
    "            *[BasicBlock(hidden_dim, hidden_dim, dropout_p)\n",
    "              for _ in range(hidden_layers)],\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlIq8JeqvvHC"
   },
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "iIHn79Iav1ri",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data prarameters\n",
    "# TODO: change the value of \"concat_nframes\" for medium baseline\n",
    "# the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
    "concat_nframes = 21\n",
    "# the ratio of data used for training, the rest will be used for validation\n",
    "train_ratio = 0.75\n",
    "\n",
    "# training parameters\n",
    "seed = 19871201          # random seed\n",
    "batch_size = 512        # batch size\n",
    "num_epoch = 3         # the number of training epoch\n",
    "learning_rate = 1e-3      # learning rate\n",
    "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
    "\n",
    "# model parameters\n",
    "# TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
    "# the input dim of the model, you should not change the value\n",
    "input_dim = 39 * concat_nframes\n",
    "hidden_layers = 2        # the number of hidden layers\n",
    "hidden_dim = 1750           # the hidden dim\n",
    "dropout_p = 0.25\n",
    "\n",
    "# env related\n",
    "commonPath = './libriphone'\n",
    "if Current_Env['inKaggle'] is True:\n",
    "    commonPath = '/kaggle/working/libriphone'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIUFRgG5yoDn"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "c1zI3v5jyrDn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "[Dataset] - # phone classes: 41, number of utterances for train: 2571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2571it [00:10, 248.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([1580384, 819])\n",
      "torch.Size([1580384])\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "858it [00:03, 256.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([536410, 819])\n",
      "torch.Size([536410])\n"
     ]
    }
   ],
   "source": [
    "same_seeds(seed)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE: {device}')\n",
    "\n",
    "# preprocess data\n",
    "train_X, train_y = preprocess_data(split='train', feat_dir=commonPath + '/feat', phone_path=commonPath,\n",
    "                                   concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
    "val_X, val_y = preprocess_data(split='val', feat_dir=commonPath + '/feat', phone_path=commonPath,\n",
    "                               concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
    "\n",
    "# get dataset\n",
    "train_set = LibriDataset(train_X, train_y)\n",
    "val_set = LibriDataset(val_X, val_y)\n",
    "\n",
    "# remove raw feature to save memory\n",
    "del train_X, train_y, val_X, val_y\n",
    "gc.collect()\n",
    "\n",
    "# get dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwWH1KIqzxEr"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试默认配置下,各显卡的表现\n",
    "- 本地显卡：168秒\n",
    "- Kaggle: T100 239秒\n",
    "- Colab: 200秒以上\n",
    "\n",
    "结论：本地显卡>Kaggle>Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "CdMWsBs7zzNs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 96.67it/s] \n",
      "100%|██████████| 1048/1048 [00:04<00:00, 211.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/003] Train Acc: 0.62517 Loss: 1.20737 | Val Acc: 0.67080 loss: 1.04838\n",
      "saving model with acc 0.67080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 99.05it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 199.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/003] Train Acc: 0.68909 Loss: 0.97679 | Val Acc: 0.69501 loss: 0.97219\n",
      "saving model with acc 0.69501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3087/3087 [00:31<00:00, 98.73it/s] \n",
      "100%|██████████| 1048/1048 [00:05<00:00, 185.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003/003] Train Acc: 0.71886 Loss: 0.87231 | Val Acc: 0.70744 loss: 0.93791\n",
      "saving model with acc 0.70744\n",
      "concat_nframes: 21 ,num_epoch: 3 ,learning_rate: 0.001 ,Dropout:\n",
      "total train start at: 2023-11-17 15:26:42.056066 ,cost:  1 minutes 50 seconds (total seconds: 110 s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# log train start time\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# create model, define a loss function, and optimizer\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers,\n",
    "                   hidden_dim=hidden_dim, dropout_p=dropout_p).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epoch):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train()  # set the model to training mode\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        features, labels = batch\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # get the index of the class with the highest probability\n",
    "        _, train_pred = torch.max(outputs, 1)\n",
    "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(val_loader)):\n",
    "            features, labels = batch\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, val_pred = torch.max(outputs, 1)\n",
    "            # get the index of the class with the highest probability\n",
    "            val_acc += (val_pred.cpu() == labels.cpu()).sum().item()\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n",
    "\n",
    "    # if the model improves, save a checkpoint at this epoch\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n",
    "\n",
    "# log train cost time\n",
    "print('total train start at:', starttime)\n",
    "print('concat_nframes:', concat_nframes, ',num_epoch:',\n",
    "      num_epoch, ',learning_rate:', learning_rate, ',Dropout:')\n",
    "totalseconds = (datetime.datetime.now()-starttime).seconds\n",
    "print('total train cost: ', math.floor(totalseconds/60),\n",
    "      'minutes', totalseconds % 60, 'seconds (total seconds:', totalseconds, 's).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "ab33MxosWLmG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_set, val_set\n",
    "del train_loader, val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Hi7jTn3PX-m"
   },
   "source": [
    "# Testing\n",
    "Create a testing dataset, and load model from the saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "VOG1Ou0PGrhc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for test: 857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "857it [00:03, 239.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([527364, 819])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat',\n",
    "                         phone_path='./libriphone', concat_nframes=concat_nframes)\n",
    "test_set = LibriDataset(test_X, None)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "ay0Fu8Ovkdad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers,\n",
    "                   hidden_dim=hidden_dim, dropout_p=dropout_p).to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp-DV1p4r7Nz"
   },
   "source": [
    "Make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "84HU5GGjPqR0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1031/1031 [00:05<00:00, 193.31it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([], dtype=np.int32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        features = batch\n",
    "        features = features.to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "\n",
    "        # get the index of the class with the highest probability\n",
    "        _, test_pred = torch.max(outputs, 1)\n",
    "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyZqy40Prz0v"
   },
   "source": [
    "Write prediction to a CSV file.\n",
    "\n",
    "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuljYSPHcZir"
   },
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(pred):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
